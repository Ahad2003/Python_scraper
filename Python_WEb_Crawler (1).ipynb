{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Define the query and the number of results to scrape\n",
        "query = 'site:youtube.com'\n",
        "num_results = 1000\n",
        "# Set the starting index for the search results\n",
        "start_index = 0\n",
        "\n",
        "# Initialize a list to store the channel links\n",
        "channel_links = []\n",
        "\n",
        "# Perform the search and scrape the results\n",
        "while start_index < num_results:\n",
        "    # Make a request to the Google search API\n",
        "    url = f'https://www.google.com/search?q={query}&start={start_index}'\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find the search result links\n",
        "    result_divs = soup.find_all('div', {'class': 'yuRUbf'})\n",
        "    for div in result_divs:\n",
        "        link = div.find('a')['href']\n",
        "        if 'youtube.com/channel/' in link:\n",
        "            channel_id = re.search(r'/channel/([^/?]+)', link)\n",
        "            if channel_id:\n",
        "                channel_link = f'https://www.youtube.com/channel/{channel_id.group(1)}'\n",
        "                channel_links.append(channel_link)\n",
        "\n",
        "    # Update the start index for the next page of results\n",
        "    start_index += 10\n",
        "\n",
        "    # Break the loop if we have collected enough results\n",
        "    if len(channel_links) >= num_results:\n",
        "        break\n",
        "\n",
        "# Save the channel links to a CSV file\n",
        "with open('youtube_channel_links.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Channel Links'])\n",
        "    writer.writerows([[link] for link in channel_links])\n",
        "\n",
        "print(f\"Total channel links scraped: {len(channel_links)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRufcq0UfaBS",
        "outputId": "bec2256a-1eb4-445b-bfca-fb9b68f12fa8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total channel links scraped: 0\n"
          ]
        }
      ]
    }
  ]
}